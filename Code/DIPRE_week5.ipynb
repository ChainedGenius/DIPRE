{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding:utf-8\n",
    "import re\n",
    "import pymysql\n",
    "import requests\n",
    "import MySQLdb\n",
    "from bs4 import BeautifulSoup\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "CONST_M = 20 # 定义常量m，在记录事件时使用，即默认先获取prefix及suffix的20个字符\n",
    "CONST_MAXBOOK = 50000 # 定义常量，获取书籍的最大数量\n",
    "db = pymysql.connect(\"localhost\",\"root\",\"\",\"DIPRE\" ) # 连接数据库\n",
    "cursor = db.cursor()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrawlWeb(path):\n",
    "    html = requests.get(path)\n",
    "    soup = BeautifulSoup(html.text)\n",
    "    body = soup.body\n",
    "    return str(body) # 这里一定要注意转化成字符串，不然返回的是soup对象\n",
    "\n",
    "def DelHrefInString(string):\n",
    "    return re.sub('href=\"(.*?)\"',\"\",string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetData(): # 获取数据库中未处理的网页，以列表—字典的形式返回\n",
    "    cursor = db.cursor()\n",
    "    sql = \"select * from webpage where mark = 0\"\n",
    "    data = []\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        for row in results:\n",
    "            each = {}\n",
    "            each['id'] = row[0]\n",
    "            each['url'] = row[1]\n",
    "            #each['text'] = DelHrefInString(CrawlWeb(row[1]))\n",
    "            #each['url'] = row[1].lstrip('http://').lstrip('https://') # 截取掉http后获取URL\n",
    "            data.append(each)\n",
    "    except:\n",
    "        db.rollback()\n",
    "    cursor.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 20, 'author': 'Jonathan Swift', 'title': 'GULLIVERâ\\x80\\x99S TRAVELS'},\n",
       " {'id': 21, 'author': 'Charles Dickens', 'title': 'Pickwick Papers'},\n",
       " {'id': 22, 'author': 'Nicholas Sparks', 'title': 'The Last Song'},\n",
       " {'id': 23, 'author': 'Charles Dickens', 'title': 'Great Expectations'},\n",
       " {'id': 27, 'author': 'Adams, Richard', 'title': 'Plague Dogs'},\n",
       " {'id': 28,\n",
       "  'author': 'Barry, John, Shepherd, Nigel',\n",
       "  'title': 'Rock Climbing (Adventure Sports)'},\n",
       " {'id': 29,\n",
       "  'author': 'David Hays, Daniel Hays',\n",
       "  'title': 'My Old Man and the Sea: A Father and Son Sail Around Cape Horn'},\n",
       " {'id': 61, 'author': '冯唐', 'title': '无所畏'},\n",
       " {'id': 63, 'author': '李诞', 'title': '笑场'},\n",
       " {'id': 406, 'author': '兰陵笑笑生', 'title': '金瓶梅(全两册)(崇祯版)(简体横排、无批评)'},\n",
       " {'id': 407, 'author': '蒙曼', 'title': '蒙曼品最美唐诗：人生五味'},\n",
       " {'id': 408, 'author': '慈怀读书会', 'title': '你最好的样子就是做自己'},\n",
       " {'id': 409, 'author': '蔡崇达', 'title': '皮囊'},\n",
       " {'id': 410, 'author': '蒋方舟', 'title': '东京一年'},\n",
       " {'id': 411, 'author': '慈怀读书会', 'title': '把生活过成你想要的样子'},\n",
       " {'id': 412,\n",
       "  'author': '上彊村民',\n",
       "  'title': '宋词三百首(作家榜经典文库，马未都推荐版！直抵生活美学的源头，遇见内心向往的生活！全新未删节插图珍藏版)大星文化出品'},\n",
       " {'id': 413, 'author': '鲁迅', 'title': '鲁迅自编文集（套装共21册）'},\n",
       " {'id': 414, 'author': '林清玄', 'title': '在这坚硬的世界里,修得一颗柔软心'},\n",
       " {'id': 415,\n",
       "  'author': '（美）德博拉·海登,（英）乔治·奥威尔,鲁思·本尼迪克特 等',\n",
       "  'title': '私家珍藏人文书库(套装共16册)'},\n",
       " {'id': 416, 'author': '贾平凹', 'title': '自在独行【百万册精装纪念版】'},\n",
       " {'id': 417, 'author': '（日）村上春树', 'title': '假如真有时光机'},\n",
       " {'id': 418, 'author': '乔瑞玲', 'title': '董卿：做一个有才情的女子'},\n",
       " {'id': 419, 'author': '余华', 'title': '余华：我们生活在巨大的差距里'},\n",
       " {'id': 420, 'author': '于谦', 'title': '玩儿'},\n",
       " {'id': 421, 'author': '海子', 'title': '海子的诗'},\n",
       " {'id': 422, 'author': '[日]村上春树(著);施小炜(译)', 'title': '我的职业是小说家'},\n",
       " {'id': 423,\n",
       "  'author': '[美]阿尔伯特·哈伯德,[奥]西格蒙德·佛洛伊德,[奥]阿尔弗雷德·阿德勒,[清]曾国藩,[清]李鸿章 等',\n",
       "  'title': '慢读?传世经典（套装共18册）'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetSeeds(): # 获取数据库中的所有种子\n",
    "    cursor = db.cursor()\n",
    "    sql = \"select * from seeds\"\n",
    "    seeds = []\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        for row in results:\n",
    "            each = {}\n",
    "            each['id'] = row[0]\n",
    "            each['author'] = row[1]\n",
    "            each['title'] = row[2]\n",
    "            seeds.append(each)\n",
    "    except:\n",
    "        db.rollback()\n",
    "    cursor.close()\n",
    "    return seeds\n",
    "seeds = GetSeeds()\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPatterns(): # 获取数据库中的所有模式\n",
    "    cursor = db.cursor()\n",
    "    sql = \"select * from patterns\"\n",
    "    patterns = []\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        for row in results:\n",
    "            each = {}\n",
    "            each['id'] = row[0]\n",
    "            each['order'] = row[1]\n",
    "            each['urlprefix'] = row[2]\n",
    "            each['prefix'] = row[3]\n",
    "            each['middle'] = row[4]\n",
    "            each['suffix'] = row[5]\n",
    "            patterns.append(each)\n",
    "    except:\n",
    "        db.rollback()\n",
    "    cursor.close()\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveSeed(author,title): # 将查找到的书籍元组存储到数据库中\n",
    "    cursor = db.cursor()\n",
    "    sql = 'INSERT INTO seeds(author,title) VALUES (\"%s\",\"%s\")' % (author , title)\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "        print(\"元组添加成功\")\n",
    "    except:\n",
    "        db.rollback()\n",
    "        print(\"元组添加失败\")\n",
    "    cursor.close()\n",
    "    \n",
    "def FindSeed(author,title):\n",
    "    cursor = db.cursor()\n",
    "    sql = 'select * from seeds where author = \"%s\" and title = \"%s\"' % (author,title)\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        res = cursor.fetchone()\n",
    "        if res is not None:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        db.rollback()\n",
    "    return 0\n",
    "\n",
    "def SavePattern(order,urlprefix,prefix,middle,suffix): # 将查找到的模式存储到数据库中\n",
    "    cursor = db.cursor() # MySQLdb.escape_string()函数返回的字符串是byte类型的，需要重新解码成Unicode，还要双引号在外单引号在内\n",
    "    sql = \"INSERT INTO patterns(order_p,urlprefix,prefix,middle,suffix) VALUES (%d,'%s','%s','%s','%s')\" % (order,MySQLdb.escape_string(urlprefix).decode('utf-8'),MySQLdb.escape_string(prefix).decode('utf-8'),MySQLdb.escape_string(middle).decode('utf-8'),MySQLdb.escape_string(suffix).decode('utf-8'))\n",
    "#     print(MySQLdb.escape_string(urlprefix).decode('utf-8')) \n",
    "    print(sql)\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "        print(\"模式添加成功\")\n",
    "    except:\n",
    "        db.rollback()\n",
    "        print(\"模式添加失败\")\n",
    "    cursor.close()\n",
    "\n",
    "def FindPattern(order,urlprefix,prefix,middle,suffix):\n",
    "    cursor = db.cursor()\n",
    "    sql = \"select * from patterns where order_p = %d and urlprefix ='%s' and prefix = '%s' and middle = '%s' and suffix = '%s'\" % (order,urlprefix,prefix,middle,suffix)\n",
    "    print(sql)\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        res = cursor.fetchone()\n",
    "        if res is not None:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        db.rollback()\n",
    "    return 0\n",
    "\n",
    "def MarkPage(id): # 通过ID标记一个网页已经搜索完成\n",
    "    cursor = db.cursor()\n",
    "    sql = \"update webpage set mark=1 where id = %d\" % (id)\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "        print(\"标记修改成功\")\n",
    "    except:\n",
    "        db.rollback()\n",
    "        print(\"标记修改失败\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBooksByPattern(pattern,text): # 通过一个模式在网页数据中查找元组并返回存储\n",
    "    NewPattern = re.compile(pattern['prefix']+'(.*?)'+pattern['middle']+'(.*?)'+pattern['suffix'],re.I) # 忽略大小写进行查询\n",
    "    m = NewPattern.finditer(text)\n",
    "    if m is not None:\n",
    "        for item in m:\n",
    "            author = item.groups()[0].strip()\n",
    "            title = item.groups()[1].strip()\n",
    "            print(author,title)\n",
    "            if FindSeed(author,title) == 0:\n",
    "                SaveSeed(author,title)\n",
    "        return 1 # 查找到了则返回1\n",
    "    return None # 没有找到返回空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchNearest(author,posTitle,string): # 查询文本中，取离title最近的author\n",
    "    pattern = re.compile(author,re.I) # 忽略大小写进行查询\n",
    "    m = pattern.finditer(string)\n",
    "    minDistance = len(string)\n",
    "    posAuthor = string.index(author)\n",
    "    for item in m:\n",
    "        dis = item.span()[0] - posTitle\n",
    "        if dis < 0:\n",
    "            dis = -dis\n",
    "        if dis < minDistance:\n",
    "            minDistance = dis\n",
    "            posAuthor = item.span()[0]\n",
    "    return posAuthor\n",
    "# pos = SearchNearest('余华',6,data[1]['text'])\n",
    "# print(data[1]['text'][pos-10:pos+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchSeedInPage(author,title,url,line): # 在文章中搜索一个种子的元组对并记录事件\n",
    "    occurrence = {}\n",
    "    if author in line and title in line: # 作者和标题都在该行则记录事件,需要先判定是作者在前还是标题在前\n",
    "        posT = line.index(title)\n",
    "#         posA = line.index(author)\n",
    "        posA = SearchNearest(author,posT,line) # 搜索离标题最近的作者位置\n",
    "        if(posA<posT): # 如果作者在前则为1，否则为0\n",
    "            order = 1\n",
    "            if posA-CONST_M>=0:\n",
    "                prefix = line[posA-CONST_M:posA] # 记录author前m个字符作为前缀\n",
    "            else:\n",
    "                prefix = line[:posA] # 如果前m个字符超出下界则m记为0\n",
    "            middle = line[posA+len(author):posT]\n",
    "            suffix = line[posT+len(title):posT+len(title)+CONST_M] # 记录title后m个字符作为后缀，后界不用if，因为默认超出len按len计算\n",
    "        else:\n",
    "            order = 0\n",
    "            if posT-CONST_M>=0:\n",
    "                prefix = line[posT-CONST_M:posT]\n",
    "            else:\n",
    "                prefix = line[:posT]\n",
    "            middle = line[posT+len(title):posA]\n",
    "            suffix = line[posA+len(author):posA+len(author)+CONST_M]\n",
    "        occurrence['author'] = author # 记录事件并返回\n",
    "        occurrence['title'] = title\n",
    "        occurrence['order'] = order\n",
    "        occurrence['url'] = url\n",
    "        occurrence['prefix'] = prefix.strip()\n",
    "        occurrence['middle'] = middle.strip()\n",
    "        occurrence['suffix'] = suffix.strip()\n",
    "        return occurrence\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchSeedsInText(seeds,page): # 在一个数据中搜索所有种子\n",
    "    occurrences = [] # 事件列表\n",
    "    for seed in seeds:\n",
    "        occurrence = SearchSeedInPage(seed['author'],seed['title'],page['url'],page['text'])\n",
    "        if occurrence is not None:\n",
    "            occurrences.append(occurrence)\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WhetherFormPattern(occurrences): # 判断同个页面的事件集能否形成事件，即middle和order是否相同\n",
    "    order = occurrences[0]['order']\n",
    "    middle = occurrences[0]['middle']\n",
    "    for item in occurrences:\n",
    "        if order != item['order'] or middle != item['middle']:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def FormPattern(occurrences): # 利用查找到的事件形成模式，此时的事件集>2，且在同个url下\n",
    "    prefix = occurrences[0]['prefix'] # 匹配数据中公共的前缀，不保证不为空\n",
    "    suffix = occurrences[0]['suffix']\n",
    "    pattern = {}\n",
    "    \n",
    "    for index in range(len(occurrences)-1,-1,-1):  # 这里的操作是默认前缀为第一个数据，然后与后面的数据进行匹配，在第一个数据的基础上做缩减操作\n",
    "        i = len(prefix)-1\n",
    "        j = len(occurrences[index]['prefix'])-1\n",
    "        while i>=0 and j>=0 and occurrences[index]['prefix'][j] == prefix[i]:\n",
    "            i = i-1\n",
    "            j = j-1\n",
    "        prefix = prefix[i+1:]\n",
    "        \n",
    "        m = 0\n",
    "        n = 0\n",
    "        while m<len(suffix) and n<len(occurrences[index]['suffix']) and occurrences[index]['suffix'][n] == suffix[m]:\n",
    "            m = m+1\n",
    "            n = n+1\n",
    "        suffix = suffix[:m]\n",
    "        \n",
    "    pattern['order'] = occurrences[0]['order']\n",
    "    pattern['middle'] = occurrences[0]['middle'].strip()\n",
    "    pattern['urlprefix'] = occurrences[0]['url'].lstrip('http://').lstrip('https://').split('/')[0] # 去除http头，并取主网址，保存url\n",
    "    pattern['prefix'] = prefix.strip()\n",
    "    pattern['suffix'] = suffix.strip()\n",
    "    if len(pattern['prefix']) and len(pattern['suffix']) and len(pattern['urlprefix']) and len(pattern['middle']): # 只返回符合特异性的模式\n",
    "        return pattern\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMatchPattern(patterns,url): #查询某个网页是否有匹配的模式，返回匹配的第一个模式\n",
    "    if patterns is None: # None不能进行迭代\n",
    "        return None\n",
    "    for item in patterns:\n",
    "        if item['urlprefix'] in url:\n",
    "            if FindBooksByPattern(item,data[index]['text']) is not None: # 如果通过该匹配模式找到事件并存储，则返回1\n",
    "                return 1\n",
    "    return 0 # 没有找到匹配的模式或者没有通过匹配模式查找到事件则返回0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "村上春树 海边的卡夫卡\n",
      "元组添加成功\n",
      "李尚龙 人设\n",
      "元组添加成功\n",
      "(日)东野圭吾 白夜行(易烊千玺、邓伦推荐，东野圭吾无冕之王我一直走在白夜里，从来就没有太阳，所以不怕失去)\n",
      "元组添加成功\n",
      "加西亚·马尔克斯 百年孤独 马尔克斯代表作\n",
      "元组添加成功\n",
      "常书欣 余罪：我的刑侦笔记(1-8册)\n",
      "元组添加成功\n",
      "威廉·萨默赛特·毛姆 毛姆作品集（套装共12册）\n",
      "元组添加成功\n",
      "（日）东野圭吾 黎明之街(我的世界在16岁崩塌了，我再无法相信任何人东野圭吾突破之作，比肩《白夜行》《秘密》)\n",
      "元组添加成功\n",
      "阿尔贝·加缪 局外人\n",
      "元组添加成功\n",
      "林奕含 房思琪的初恋乐园\n",
      "元组添加成功\n",
      "詹姆斯•乔伊斯,萧乾,文洁若（译） 尤利西斯\n",
      "元组添加成功\n",
      "宁航一 怪奇物语·噩梦\n",
      "元组添加成功\n",
      "余华 活着（余华经典著作）\n",
      "元组添加成功\n",
      "维尔吉妮·格里马尔蒂 我余生的第一天\n",
      "元组添加成功\n",
      "刘慈欣 三体全集(全3册)\n",
      "元组添加成功\n",
      "（日）东野圭吾 东野圭吾：悲剧人偶\n",
      "元组添加成功\n",
      "老甄 心理师(共5册)\n",
      "元组添加成功\n",
      "孙皓晖 大秦帝国(套装共17卷)\n",
      "元组添加成功\n",
      "古龙 陆小凤传奇(全7册)\n",
      "元组添加成功\n",
      "高罗佩,黄禄善,陈海东等（译） 大唐狄公案(全6册)\n",
      "元组添加成功\n",
      "（日）太宰治 人间失格 李现推荐\n",
      "元组添加成功\n",
      "标记修改成功\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    flag = 0 # 跳出循环的标志\n",
    "    patterns = GetPatterns()\n",
    "    data = GetData() # 获取所有没有被处理过的数据\n",
    "    seeds = GetSeeds() # 获取所有种子\n",
    "    \n",
    "    for index in range(len(data)-1,-1,-1): # 因为中途需要删除数据，所以从后往前遍历\n",
    "        \n",
    "        data[index]['text'] = DelHrefInString(CrawlWeb(data[index]['url']))\n",
    "#         print(type(data[index]['text']))\n",
    "        res = GetMatchPattern(patterns,data[index]['url']) # 对于每组数据，首先查找是否有现有匹配模式\n",
    "        if res == 1: # 如果通过匹配模式匹配到事件并存储，则标记并删除，如果没有则利用种子查询\n",
    "            MarkPage(data[index]['id']) # 标记该网页已查询\n",
    "            del data[index] # 在内存中删除处理过的数据\n",
    "            continue # 处理下一个网页\n",
    "                \n",
    "#         # 如果没有匹配的模式，或者利用匹配模式查出来的结果为空，则进行以下步骤\n",
    "        occurrences = SearchSeedsInText(seeds,data[index]) # 在该条数据中搜索所有种子对，并记录成事件集\n",
    "        if occurrences is not None:\n",
    "            if len(occurrences)<2: # 如果种子查询个数仅仅为1，则无法形成事件（后续改为存储到数据库中）\n",
    "                continue\n",
    "            if WhetherFormPattern(occurrences): # 如果事件集具有相同的middle和order则尝试形成模式\n",
    "                pattern = FormPattern(occurrences)\n",
    "                print(pattern)\n",
    "                if pattern is not None: # 如果形成有效的模式，则利用模式在该页面下搜索\n",
    "                    SavePattern(pattern['order'],pattern['urlprefix'],pattern['prefix'],pattern['middle'],pattern['suffix']) # 直接存储\n",
    "                    FindBooksByPattern(pattern,data[index]['text']) # 通过形成的模式查找元组并存储\n",
    "            MarkPage(data[index]['id']) # 处理完成后，删除该数据，并将网页标记为已搜索\n",
    "            del data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': '4.html'}\n"
     ]
    }
   ],
   "source": [
    "test = [{'url':'1.html'},{'url':'2.html'},{'url':'3.html'},{'url':'4.html'}] # 删除一个列表中的元组，则后面的元组自动往前\n",
    "del test[2]\n",
    "print(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
